ğŸ”Š RAG-Based Audioâ€“Video Knowledge Extraction Assistant
Transform your own recordings into a searchable, intelligent AI knowledge system.

This project enables you to convert any set of videos into text, index them using vector embeddings, and query them through an LLM that retrieves information grounded in your data.

Once your dataset is processed, you can ask questions like:
- â€œWhere was this specific topic mentioned?â€
- â€œWhich part talked about X?â€
- â€œSummarize the key points related to Y.â€

The assistant uses Retrieval-Augmented Generation (RAG) to find the most relevant segments from your files and generate accurate, context-aware answers.

ğŸ“ How to Use This Assistant on Your Own Data
Below is a clean, professional, and complete workflow.

âœ… Step 1 â€” Add Your Video Files: Place all your raw video recordings inside the /videos directory.

Supported input formats: .mp4, .mov, .mkv,.avi

Tip: Use descriptive filenames so you can easily map AI responses back to original files later.

ğŸ§ Step 2 â€” Extract Audio (Convert Video â†’ MP3)

Run the conversion script:

python video_to_mp3.py

This step will:

Scan the /videos folder

Convert each video into an .mp3 file

Save all audio outputs insidethe /audio directory

Preserve naming structure for consistency

Why?
ğŸ‘‰ Processing audio is significantly faster and more efficient for transcription and embedding.

ğŸ“ Step 3 â€” Generate Text Data (MP3 â†’ JSON)

Use the transcription script to convert all audio files into structured JSON files:

python mp3_to_json.py


Each generated JSON file contains:

Cleaned transcript text

Timestamped segments

Structured grouping for downstream vectorization

Your /json folder will now contain text-based versions of all your recordings.

ğŸ§  Step 4 â€” Create Vector Embeddings (JSON â†’ Embedding Store)

Convert the JSON transcripts into vector embeddings using the preprocessing script:

python preprocess_json.py


This step generates:

A dataframe with:

Chunked text

Associated timestamps

Embedding vectors

Metadata fields

A Joblib (.pkl) file that stores your embedding index efficiently
(e.g., embeddings_store.pkl)

Why?
ğŸ‘‰ These embeddings allow the system to search and retrieve exactly the portions of your dataset that relate to a user query.

ğŸ¤– Step 5 â€” Ask Questions Using the LLM (RAG Stage)

Load your embedding store:

from joblib import load
embeddings_df = load("embeddings_store.pkl")


Now the assistant will:

Take the userâ€™s question

Retrieve the most relevant text chunks using similarity search

Construct a context-rich prompt

Send this prompt to the LLM

Return an accurate answer grounded in your original data

You can ask questions such as:
- â€œWhere is X mentioned?â€
- â€œSummarize all points related to Y.â€
- â€œFind portions where Z is discussed.â€
- â€œGive a structured explanation of everything related to Topic A.â€

ğŸ“Š End-to-End Workflow Overview: Videos â†’ Audio â†’ Text â†’ Embeddings â†’ RAG Querying â†’ AI Answers

âš™ï¸ Tips for Best Output Quality
Use clear audio for better transcription
Keep filenames descriptive
Re-run the embedding script whenever you add new files
Maintain a consistent directory structure
